{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651d275",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuración (puedes ajustar estos parámetros)\n",
    "CSV_PATHS = ['data/demographic.csv', '../data/demographic.csv', '../../data/demographic.csv']\n",
    "TARGET_COL = 'INDFMPIR'  # Columna objetivo para correlaciones\n",
    "MIN_ABS_CORR_IMPORTANT = 0.3  # Umbral de correlación para considerar 'importante'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# 1. Localizar el archivo CSV\n",
    "csv_file = None\n",
    "for p in CSV_PATHS:\n",
    "    if os.path.exists(p):\n",
    "        csv_file = p\n",
    "        break\n",
    "if csv_file is None:\n",
    "    print(f\"Error: No se encontró demographic.csv en rutas: {CSV_PATHS}\")\n",
    "    sys.exit(1)\n",
    "print(f\"Usando archivo: {csv_file}\")\n",
    "\n",
    "# 2. Leer CSV\n",
    "print(\"Leyendo el CSV...\")\n",
    "df = pd.read_csv(csv_file)\n",
    "original_columns = df.columns.tolist()\n",
    "\n",
    "# 3. Normalizar missing values (empty strings -> NaN)\n",
    "df.replace(['', ' '], pd.NA, inplace=True)\n",
    "\n",
    "# 4. Asegurar que la columna objetivo existe\n",
    "if TARGET_COL not in df.columns:\n",
    "    print(f\"Advertencia: La columna objetivo '{TARGET_COL}' no está en el dataset. Solo se aplicarán reglas por % de missing.\")\n",
    "\n",
    "# 5. Calcular % de missing por columna\n",
    "missing_counts = df.isna().sum()\n",
    "missing_pct = missing_counts / len(df)\n",
    "\n",
    "# 6. Preparar correlaciones respecto a TARGET_COL (solo numéricas)\n",
    "if TARGET_COL in df.columns:\n",
    "    # Convertir a numérico lo que se pueda\n",
    "    numeric_df = df.select_dtypes(include=[np.number]).copy()\n",
    "    # Intento de conversión suave para columnas object\n",
    "    for col in df.columns:\n",
    "        if col not in numeric_df.columns:\n",
    "            try:\n",
    "                numeric_df[col] = pd.to_numeric(df[col])\n",
    "            except Exception:\n",
    "                pass\n",
    "    if TARGET_COL in numeric_df.columns:\n",
    "        corr_series = numeric_df.corr(numeric_only=True)[TARGET_COL].drop(labels=[TARGET_COL], errors='ignore')\n",
    "    else:\n",
    "        corr_series = pd.Series(dtype=float)\n",
    "        print(f\"No se puede calcular correlaciones: '{TARGET_COL}' no es numérica o convertible.\")\n",
    "else:\n",
    "    corr_series = pd.Series(dtype=float)\n",
    "\n",
    "# 7. Visualización de la matriz de correlaciones (solo numéricas) si procede\n",
    "if len(df.select_dtypes(include=[np.number]).columns) > 1:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df.select_dtypes(include=[np.number]).corr(numeric_only=True), cmap='coolwarm', center=0, annot=False)\n",
    "    plt.title('Matriz de correlaciones (numéricas)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay suficientes columnas numéricas para un heatmap de correlaciones.\")\n",
    "\n",
    "# 8. Decisión de eliminación según reglas\n",
    "cols_drop = []\n",
    "reasons = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    if col == TARGET_COL:\n",
    "        continue\n",
    "    pct = missing_pct[col]\n",
    "    corr_val = corr_series.get(col, np.nan)\n",
    "    abs_corr = abs(corr_val) if not np.isnan(corr_val) else np.nan\n",
    "\n",
    "    # Reglas:\n",
    "    # > 50% eliminar siempre\n",
    "    if pct > 0.50:\n",
    "        cols_drop.append(col)\n",
    "        reasons[col] = f\"Missing {pct:.1%} > 50%\"\n",
    "        continue\n",
    "    # > 40%-50% eliminar salvo justificación fuerte -> aquí eliminamos\n",
    "    if 0.40 < pct <= 0.50:\n",
    "        cols_drop.append(col)\n",
    "        reasons[col] = f\"Missing {pct:.1%} entre 40%-50% (regla general eliminar)\"\n",
    "        continue\n",
    "    # 20%-40% mantener solo si muy relevante (|corr| >= MIN_ABS_CORR_IMPORTANT)\n",
    "    if 0.20 < pct <= 0.40:\n",
    "        if np.isnan(abs_corr) or abs_corr < MIN_ABS_CORR_IMPORTANT:\n",
    "            cols_drop.append(col)\n",
    "            reasons[col] = f\"Missing {pct:.1%} y |corr| {abs_corr if not np.isnan(abs_corr) else 'NaN'} < {MIN_ABS_CORR_IMPORTANT}\"\n",
    "        continue\n",
    "    # 5%-20% eliminar si NO está correlacionada (|corr| < umbral)\n",
    "    if 0.05 < pct <= 0.20:\n",
    "        if np.isnan(abs_corr) or abs_corr < MIN_ABS_CORR_IMPORTANT:\n",
    "            cols_drop.append(col)\n",
    "            reasons[col] = f\"Missing {pct:.1%} y baja correlación (|corr| {abs_corr if not np.isnan(abs_corr) else 'NaN'} < {MIN_ABS_CORR_IMPORTANT})\"\n",
    "        continue\n",
    "    # <5% -> no eliminar ahora (imputación futura), hacer nada\n",
    "\n",
    "# 9. Aplicar eliminación\n",
    "cols_drop = sorted(set(cols_drop))\n",
    "print(\"\\nResumen decisiones de eliminación:\")\n",
    "if cols_drop:\n",
    "    for c in cols_drop:\n",
    "        print(f\" - {c}: {reasons.get(c,'(sin razón)')}\")\n",
    "else:\n",
    "    print(\"No se eliminarán columnas bajo las reglas actuales.\")\n",
    "\n",
    "print(f\"Total columnas originales: {len(original_columns)}\")\n",
    "print(f\"Total a eliminar: {len(cols_drop)}\")\n",
    "print(f\"Quedarán: {len(original_columns) - len(cols_drop)}\")\n",
    "\n",
    "# 10. Eliminar y guardar\n",
    "if cols_drop:\n",
    "    df.drop(columns=cols_drop, inplace=True, errors='ignore')\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"Dataset guardado sin {len(cols_drop)} columnas en {csv_file}\")\n",
    "else:\n",
    "    print(\"No se realizaron cambios en el CSV.\")\n",
    "\n",
    "# 11. (Opcional) Mostrar top correlaciones con TARGET_COL\n",
    "if not corr_series.empty:\n",
    "    print(\"\\nTop 10 correlaciones (abs) con INDFMPIR:\")\n",
    "    top_corr = corr_series.reindex(corr_series.abs().sort_values(ascending=False).index)\n",
    "    print(top_corr.head(10))\n",
    "\n",
    "print(\"Proceso completado.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
